apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "gateway-api-inference-extension.name" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "gateway-api-inference-extension.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.inferenceExtension.replicas | default 1 }}
  selector:
    matchLabels:
      {{- include "gateway-api-inference-extension.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "gateway-api-inference-extension.selectorLabels" . | nindent 8 }}
    spec:
      serviceAccountName: {{ include "gateway-api-inference-extension.name" . }}
      # Conservatively, this timeout should mirror the longest grace period of the pods within the pool
      terminationGracePeriodSeconds: 130
      containers:
      - name: epp
        image: {{ .Values.inferenceExtension.image.hub }}/{{ .Values.inferenceExtension.image.name }}:{{ .Values.inferenceExtension.image.tag }}
        imagePullPolicy: {{ .Values.inferenceExtension.image.pullPolicy | default "Always" }}
        args:
        - -poolName
        - {{ .Release.Name }}
        - -poolNamespace
        - {{ .Release.Namespace }}
        - -v
        - "{{ .Values.inferenceExtension.logVerbosity | default "3" }}"
        - -grpcPort
        - "9002"
        - -grpcHealthPort
        - "9003"
        - -metricsPort
        - "9090"
        - -configFile
        - "config/{{ .Values.inferenceExtension.pluginsConfigFile }}"
        # https://pkg.go.dev/flag#hdr-Command_line_flag_syntax; space is only for non-bool flags
        - "-enablePprof={{ .Values.inferenceExtension.enablePprof }}"
        {{- if eq (.Values.inferencePool.modelServerType | default "vllm") "triton-tensorrt-llm" }}
        - -totalQueuedRequestsMetric
        - "nv_trt_llm_request_metrics{request_type=waiting}"
        - -kvCacheUsagePercentageMetric
        - "nv_trt_llm_kv_cache_block_metrics{kv_cache_block_type=fraction}"
        - -loraInfoMetric
        - "" # Set an empty metric to disable LoRA metric scraping as they are not supported by Triton yet.
        {{- end }}
        ports:
        - name: grpc
          containerPort: 9002
        - name: grpc-health
          containerPort: 9003
        - name: metrics
          containerPort: 9090
        {{- with .Values.inferenceExtension.extraContainerPorts }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
        livenessProbe:
          grpc:
            port: 9003
            service: inference-extension
          initialDelaySeconds: 5
          periodSeconds: 10
        readinessProbe:
          grpc:
            port: 9003
            service: inference-extension
          initialDelaySeconds: 5
          periodSeconds: 10
        {{- with .Values.inferenceExtension.env }}
        env:
        {{- toYaml . | nindent 8 }}
        {{- end }}
        volumeMounts:
        - name: plugins-config-volume
          mountPath: "/config"
      volumes:
      - name: plugins-config-volume
        configMap:
          name: {{ include "gateway-api-inference-extension.name" . }}
